{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/omegamlpy3/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0807 21:04:09.068856 140607210473216 deprecation.py:323] From /usr/local/anaconda3/envs/omegamlpy3/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0807 21:04:09.102207 140607210473216 deprecation.py:323] From /usr/local/anaconda3/envs/omegamlpy3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0807 21:04:09.106480 140607210473216 deprecation.py:323] From /usr/local/anaconda3/envs/omegamlpy3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0807 21:04:09.131568 140607210473216 deprecation.py:323] From <ipython-input-1-3ffc345de555>:33: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0807 21:04:09.144209 140607210473216 deprecation.py:506] From /usr/local/anaconda3/envs/omegamlpy3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0807 21:04:09.533163 140607210473216 deprecation.py:323] From <ipython-input-1-3ffc345de555>:36: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "W0807 21:04:09.665901 140607210473216 deprecation.py:323] From <ipython-input-1-3ffc345de555>:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0807 21:04:10.002835 140607210473216 deprecation.py:323] From <ipython-input-1-3ffc345de555>:51: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0807 21:04:10.099891 140607210473216 deprecation.py:323] From /usr/local/anaconda3/envs/omegamlpy3/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0807 21:04:10.438200 140607210473216 deprecation.py:323] From /usr/local/anaconda3/envs/omegamlpy3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0807 21:04:10.515926 140607210473216 deprecation.py:323] From /usr/local/anaconda3/envs/omegamlpy3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "W0807 21:04:10.587546 140607210473216 deprecation.py:323] From /usr/local/anaconda3/envs/omegamlpy3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0807 21:04:11.060701 140607210473216 deprecation.py:323] From /usr/local/anaconda3/envs/omegamlpy3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.0993, 'loss': 2.3028002, 'global_step': 10}\n"
     ]
    }
   ],
   "source": [
    "# sample using an Estimator model\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# load mnist dataset\n",
    "((train_data, train_labels), (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data/np.float32(255)\n",
    "train_labels = train_labels.astype(np.int32)  # not required\n",
    "\n",
    "eval_data = eval_data/np.float32(255)\n",
    "eval_labels = eval_labels.astype(np.int32)  # not required\n",
    "\n",
    "# Create the Estimator\n",
    "def make_classifier(model_dir=None):\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    def cnn_model_fn(features, labels, mode):\n",
    "      import tensorflow as tf\n",
    "      import numpy as np\n",
    "      \"\"\"Model function for CNN.\"\"\"\n",
    "      # Input Layer\n",
    "      if isinstance(features, dict):\n",
    "        features = features['x']\n",
    "      input_layer = tf.reshape(features, [-1, 28, 28, 1])\n",
    "        \n",
    "\n",
    "      # Convolutional Layer #1\n",
    "      conv1 = tf.layers.conv2d(\n",
    "          inputs=input_layer,\n",
    "          filters=32,\n",
    "          kernel_size=[5, 5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "      # Pooling Layer #1\n",
    "      pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      # Convolutional Layer #2 and Pooling Layer #2\n",
    "      conv2 = tf.layers.conv2d(\n",
    "          inputs=pool1,\n",
    "          filters=64,\n",
    "          kernel_size=[5, 5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu)\n",
    "      pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      # Dense Layer\n",
    "      pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "      dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "      dropout = tf.layers.dropout(\n",
    "          inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "      # Logits Layer\n",
    "      logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "      predictions = {\n",
    "          # Generate predictions (for PREDICT and EVAL mode)\n",
    "          \"classes\": tf.argmax(input=logits, axis=1),\n",
    "          # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "          # `logging_hook`.\n",
    "          \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "      }\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "      # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "      loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "      # Configure the Training Op (for TRAIN mode)\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "      # Add evaluation metrics (for EVAL mode)\n",
    "      eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "              labels=labels, predictions=predictions[\"classes\"])\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(\n",
    "          mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "    \n",
    "    mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=model_dir)\n",
    "    return mnist_classifier\n",
    "    \n",
    "mnist_classifier = make_classifier(model_dir=\"/tmp/mnist_convnet_model\")\n",
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])\n",
    "# evaluate\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/projects/omegaml-ce/omegaml/util.py:88: UserWarning: Using omegaml.defaults because Django was not initialized.Try importing omegaml within a method instead of at the module level\n",
      "  warn(\"Using omegaml.defaults because Django was not initialized.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Metadata: Metadata(bucket=omegaml,prefix=models/,kind=tfestimator.model,created=2019-08-07 15:43:24.046000)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can save the model so it can be reused and re-fitted on the cluster\n",
    "\n",
    "import omegaml as om \n",
    "from omegaml.backends.tensorflow import TFEstimatorModel\n",
    "\n",
    "om.datasets.put(train_data, 'mnist-X')\n",
    "om.datasets.put(train_labels, 'mnist-Y')\n",
    "\n",
    "saveable_model = TFEstimatorModel(estimator_fn=make_classifier, model=mnist_classifier)\n",
    "om.models.put(saveable_model, 'tf-model-mnist-fn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Metadata: Metadata(bucket=omegaml,prefix=models/,kind=tfestimator.model,created=2019-08-07 15:43:24.046000)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit on the cluster. this may take a while\n",
    "om.runtime.model('tf-model-mnist-fn').fit('mnist-X', 'mnist-Y').get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'classes': 3,\n",
       "  'probabilities': array([0.10335779, 0.09022784, 0.10337006, 0.11674983, 0.09886219,\n",
       "         0.09952408, 0.09712849, 0.10106223, 0.10139097, 0.08832654],\n",
       "        dtype=float32)},\n",
       " {'classes': 0,\n",
       "  'probabilities': array([0.1261076 , 0.08855822, 0.10303713, 0.10400002, 0.09997762,\n",
       "         0.10020637, 0.0962674 , 0.08965096, 0.10356303, 0.08863159],\n",
       "        dtype=float32)}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-load the model and predict from a numpy array\n",
    "train_data = om.datasets.get('mnist-X')\n",
    "\n",
    "X = train_data[0:2, :]\n",
    "\n",
    "model_ = om.models.get('tf-model-mnist-fn')\n",
    "[v for v in model_.predict(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classes</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.10335779, 0.09022784, 0.103370056, 0.116749...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.1261076, 0.08855822, 0.103037134, 0.1040000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classes                                      probabilities\n",
       "0        3  [0.10335779, 0.09022784, 0.103370056, 0.116749...\n",
       "1        0  [0.1261076, 0.08855822, 0.103037134, 0.1040000..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on the cluster via direct input as numpy, or the numpy array stored as a dataset\n",
    "train_data = om.datasets.get('mnist-X')\n",
    "\n",
    "#we can save the data as stacked images\n",
    "om.datasets.put(train_data[0:2, :], 'mnist-sample')\n",
    "om.runtime.model('tf-model-mnist-fn').predict('mnist-sample').get()\n",
    "# or just pass the data as is\n",
    "om.runtime.model('tf-model-mnist-fn').predict(train_data[0:2, :]).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Metadata: Metadata(bucket=omegaml,prefix=models/,kind=tf.savedmodel,created=2019-08-07 21:05:08.859000)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can save the model as a SavedModel using a standard or custom input fn\n",
    "# ServingInput is a helper to create a corresponding input fn from a given like=dataset\n",
    "\n",
    "from omegaml.backends.tensorflow.tfsavedmodel import ServingInput\n",
    "\n",
    "input_fn = ServingInput(features=['x'], like=train_data.reshape((-1, 28, 28, 1)))\n",
    "\n",
    "om.models.put(mnist_classifier, 'tf-model-mnist-estimator', \n",
    "              serving_input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probabilities': array([[0.09726422, 0.09969608, 0.10523612, 0.10702087, 0.10931291,\n",
       "         0.09766794, 0.09854203, 0.0988235 , 0.09508919, 0.09134707],\n",
       "        [0.09864448, 0.10165177, 0.10505242, 0.10086438, 0.11054146,\n",
       "         0.10126863, 0.09307811, 0.09533221, 0.10046625, 0.09310029]],\n",
       "       dtype=float32), 'classes': array([4, 4])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# once saved we can again use the runtime to predict\n",
    "om.datasets.put(train_data[0:2, :].reshape((-1, 28, 28, 1)), 'mnist-sample')\n",
    "om.runtime.model('tf-model-mnist-estimator').predict('mnist-sample').get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'om' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-779bf7189578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0momegaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOmegaRestApiAuth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OMEGA_RESTAPI_URL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http://localhost:5000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOmegaRestApiAuth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mnist-sample'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'om' is not defined"
     ]
    }
   ],
   "source": [
    "# or use the model REST API \n",
    "import requests\n",
    "from omegaml.client.auth import OmegaRestApiAuth\n",
    "\n",
    "url = getattr(om.defaults, 'OMEGA_RESTAPI_URL', 'http://localhost:5000')\n",
    "auth = OmegaRestApiAuth.make_from(om)\n",
    "dataset = 'mnist-sample'\n",
    "modelname = 'tf-model-mnist-estimator'\n",
    "predict_url = '{url}/api/v1/model/{modelname}/predict?datax={dataset}'.format(**locals())\n",
    "resp = requests.put(predict_url, auth=auth)\n",
    "print(predict_url)\n",
    "print(resp.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
